

大模型在专有知识问答上表现不佳，原因是模型没有见过或学习过这些知识，自然也给不出我们想要的结果。解决思路就是：让模型看见或学习这些知识。

具体的，有两条路线：

（1）模型训练：根据专有知识做一个训练数据集，然后用大模型在数据集上进行微调，让模型去学习这些知识。类似于，你给模型出了一大本练习题，包含题目和答案，手把手教他做题。等他学会了，考试遇到类似的题目，就知道怎么做了

（2）外挂知识库：在问模型问题的时候，额外给他一些专有知识中的相关信息，让他从中找到正确的答案。类似于，你给模型出了一道阅读理解题，让他先读一大段文字，然后回答问题。


从描述中大家可以看出，路线 1 实现起来相对复杂，难度较大，具有较高的门槛，此处不做详细说明；本文收集的方案都是基于路线 2 完成的，也就是外挂知识库。

实现路线2，有两个关键的步骤：（1）从知识库中挑选出与问题相关的内容。这里涉及到对文档的加载、切分、向量化、相似度比对等一系列的操作。（2）将挑选出的内容与问题，一起输入给大模型。主要涉及prompt的编写。




## **一）怎样从知识库中找到与问题相关的内容？**

  

知识库的内容一般比较多，要想模型快速、准确地回答问题，首先需要为模型提供最相关的信息。

这一步对于最终的问答效果有着非常重要的影响。试想一下，如果找到的信息太多、或者相关度不高，模型很容易迷失其中，难以给出准确的答案；类似于，你直接丢给他一本书，让他去书中寻找问题的答案，效果可想而知。另一方面，如果给的信息不足、甚至完全没有相关信息，模型也就无从参考。

那么，如何从海量的知识库中寻找与问题相关的信息？


### **1、知识库预处理**

- 加载、读取文件：读取存储在本地的知识库文件，通常是将其转化为文本格式
    
- 文本分割(Text splitter)：按照一定的规则(例如段落、句子、token数量等)将文本分割成各个部分
    
      
    

### **2、文本向量化和存储**

- 文本向量化：这通常涉及到NLP的特征抽取，可以通过诸如TF-IDF、word2vec、语言模型等方法将分割好的文本转化为数值向量，方便后续的文本相似度计算，即检索和问题相关的文本。
    
- 向量存储：文本向量化之后存储到数据库vectorstore，常见的有Pincone, Qdrant, Waviate, Milvus, Chroma等。
    

### 

### **3、问句向量化**

采用和知识库文本相同的向量化处理方式，将查询问题转为语义向量，用于问题和知识库文本之间的相似度计算。


### **4、从知识库文本中挑选 top k 个相关文本**

这一步是信息检索的核心，一般可通过余弦相似度、欧氏距离等计算方式，找出与问题向量最接近的文本向量。这样，我们就找到了知识库中与问题最相关的 top k 个文本



## **二）将挑选出的内容与问题，一起输入给大模型**

挑选出与问题的相关文本后，和问题一起组合成prompt，输入给大模型。

prompt示例如下：

```bash
已知信息：{context}

根据上述已知信息，简洁和专业的来回答用户的问题。如果无法从中得到答案，请说 “根据已知信息无法回答该问题” 或 “没有提供足够的相关信息”，不允许在答案中添加编造成分，答案请使用中文。问题是：{question}

```

其中，context部分就是相关的知识库文本，question是查询问题。




## 总结

之前Antonio 做的 ai-companion 就是使用的这种方式

向量数据库使用的是pincone
大模型使用的是replicate

